

# Paddle Hackathon ç¬¬4æœŸ ç§‘å­¦è®¡ç®—

â€”â€” ç§‘å­¦è®¡ç®—æ–¹å‘ 51

åŸæ–‡ï¼š[Deep Learning Methods for Reynolds-Averaged Navier-Stokes Simulations of Airfoil Flows](http://arxiv.org/abs/1810.08217)

å‚è€ƒï¼š[Deep-Flow-Prediction Pytorch](https://github.com/thunil/ Deep-Flow-Prediction)

- æœ¬æ–‡åŸºäºUNetè¿›è¡Œäº†æœºç¿¼ç‰©ç†åœºé¢„æµ‹ï¼Œå°†äºŒç»´ç‰©ç†åœºæ±‚è§£è¿‡ç¨‹çœ‹ä½œè®¡ç®—æœºè§†è§‰çš„å›¾åƒåˆ†å‰²ä»»åŠ¡ï¼šé¦–å…ˆå°†å‡ ä½•å½¢çŠ¶ã€æ”»è§’ç¿¼å‹å½¢çŠ¶ã€æ”»è§’å’ŒReynolds numberè½¬åŒ–ä¸ºè¾“å…¥å›¾åƒï¼Œå°†ç‰©ç†åœºï¼ˆå‹åŠ›ã€é€Ÿåº¦åœºï¼‰çœ‹ä½œè¾“å‡ºç»“æœï¼Œé‡‡ç”¨L1lossè¿›è¡Œå›å½’ä»»åŠ¡è®­ç»ƒï¼Œæ–‡ç« ä¹Ÿè¯¦ç»†æ¢è®¨äº†ä¸åŒçš„ç½‘ç»œå¤æ‚åº¦ã€è®­ç»ƒç­–ç•¥ä»¥åŠæ•°æ®å¢å¼ºæ–¹æ³•å¯¹é¢„æµ‹ç²¾åº¦çš„å½±å“ï¼Œè¿™é¡¹ç ”ç©¶å¯ä»¥æ³›åŒ–è‡³æœªçŸ¥ç¿¼å‹å½¢çŠ¶ä¸­ï¼Œè·å¾—äº†è‰¯å¥½çš„æ•ˆæœã€‚

- æœ¬æ–‡å‘è¡¨äº2018å¹´ï¼Œåœ¨å½“æ—¶æ˜¯æ¯”è¾ƒå…ˆè¿›çš„å·¥ä½œä½†ç°åœ¨çœ‹æ¥ï¼Œç”±äºä½åˆ†è¾¨ç‡çš„åƒç´ åŒ–å¤„ç†æ–¹å¼ï¼Œæ— æ³•ç²¾ç»†åŒ–åˆ»ç”»ç¿¼å‹å½¢çŠ¶ï¼Œå¯¼è‡´äº†æ˜¾è‘—çš„äººå·¥ç²—ç³™åº¦ï¼Œå¯¹è¾¹ç•Œå±‚ã€å¤§æ¢¯åº¦çš„æ¶¡é‡ä½ç½®æ— æ³•å‡†ç¡®é¢„æµ‹ï¼Œæ›´æ— æ³•é¢„æµ‹å‡†ç¡®çš„æ°”åŠ¨æ€§èƒ½å‚æ•°ï¼Œæ˜¾ç„¶ä¸å…·å¤‡å®é™…åº”ç”¨æ„ä¹‰ã€‚

- æœ¬æ–¹æ³•UNeté€šè¿‡å­¦ä¹ åˆå§‹é€Ÿåº¦åˆ†å¸ƒä»¥åŠç¿¼å‹å½¢çŠ¶ï¼Œé¢„æµ‹åœ¨ä¸å¯å‹ç¼©Navier-stokesæ–¹ç¨‹ï¼ˆReynolds-Averagedï¼šSpalart-Allmaraså•æ–¹ç¨‹æ¹æµæ¨¡å‹ï¼‰çº¦æŸä¸‹çš„ç‰©ç†åœºï¼ˆå‹åŠ›ã€é€Ÿåº¦åœºï¼‰ï¼Œæœ¬è´¨å±äºç®—å­å­¦ä¹ çš„ä¸€ç§ï¼ŒUNetæ˜¯CNN-basedçš„ç®—å­æ¨¡å‹ï¼Œ**å¯¹æ ‡è¯¥é¢†åŸŸè¿‘æ¥è¾ƒæµè¡Œçš„DeepONetã€FNOã€Transformerç­‰æ¶æ„**ã€‚

- æœ¬æ¬¡å®ŒæˆUNetã€FNOã€Transformerçš„Paddleå®ç°ï¼Œå¹¶å°†UNetä¸FNOå’ŒTransformerè¿›è¡Œäº†ç®€å•å¯¹æ¯”ï¼ˆè€ƒè™‘DeepONetä¸å¯¹ç©ºé—´å…³ç³»è¿›è¡Œå½’çº³åç½®ï¼Œå› æ­¤æœªè¿›è¡Œå¯¹æ¯”ï¼‰ï¼Œç»“æœä¹Ÿè¡¨æ˜FNOå’ŒTransformerå¯è·å¾—æ›´é«˜ç²¾åº¦ï¼Œ**ç›¸å¯¹äºåŸæ–‡ä¸­çš„ç›¸å¯¹è¯¯å·®ä»3%è¿›ä¸€æ­¥é™è‡³2%ã€‚**

## 1. ä»£ç è¯´æ˜

- **ä»£ç ç»“æ„**

  ```
  ğŸ“‚ Deep-Flow-Prediction-Paddle
  |_ğŸ“ data
    |_ğŸ“ train                    # è®­ç»ƒé›†æ•°æ®              
      |_ğŸ“ reg                    # å¸¸è§„æ•°æ®é›†    
      |_ğŸ“ shear                  # å‰ªåˆ‡æ•°æ®é›†ï¼Œé‡‡ç”¨ä¸å›¾åƒxæ–¹å‘Â±15Â°å†…çš„æ‰°åŠ¨äº§ç”Ÿå¢å¼ºæ•°æ®é›† 
      |_ğŸ“ sup                    # é«˜åˆ†è¾¨ç‡æ•°æ®é›†
    |_ğŸ“ test                     # æµ‹è¯•é›†æ•°æ®ï¼Œ90ä¸ªæ ·æœ¬     
      |_ğŸ“„ ***.npz
    |_ğŸ“ OpenFOAM                 # OpenFOAMæ•°æ®é›†ç”Ÿæˆ
    	|_ğŸ“ 0                    	# OpenFOAMåˆå§‹æ¡ä»¶å’Œè¾¹ç•Œæ¡ä»¶è®¾å®š
    	  |_ğŸ“„ nut                  # æ¹æµç²˜åº¦åˆå§‹/è¾¹ç•Œæ¡ä»¶
        |_ğŸ“„ nuTilda              # Spalart-Allmarasæ¹æµæ¨¡å‹ç”¨å˜é‡
        |_ğŸ“„ U                    # é€Ÿåº¦åˆå§‹/è¾¹ç•Œæ¡ä»¶
        |_ğŸ“„ P                    # å‹åŠ›åˆå§‹/è¾¹ç•Œæ¡ä»¶
      |_ğŸ“ constant               # OpenFOAMåˆå§‹æ¡ä»¶å’Œè¾¹ç•Œæ¡ä»¶è®¾å®š
        |_ğŸ“„ transportProperties	# æµä½“ç‰©æ€§
        |_ğŸ“„ turbulenceProperties # æ¹æµæ¨¡å‹
      |_ğŸ“ system                 # OpenFOAMæ±‚è§£å™¨è®¾ç½®
        |_ğŸ“„ controlDict          # æ±‚è§£è¿‡ç¨‹æ§åˆ¶
        |_ğŸ“„ fvSchemes            # fvmç¦»æ•£æ ¼å¼
        |_ğŸ“„ fvSolution           # æ–¹ç¨‹ç»„æ±‚è§£æ–¹æ³•
        |_ğŸ“„ internalCloud        # OpenFOAMæ±‚è§£å™¨è®¾ç½®
      |_ğŸ“„ dataGEN.py             # æ•°æ®é›†ç”Ÿæˆè„šæœ¬ï¼Œéœ€åœ¨linuxæœ¬åœ°æœºå®‰è£…openFOAMv9.0åè¿è¡Œ
      |_ğŸ“„ download_airfoils.sh   # uiucç¿¼å‹æ•°æ®é›†ä¸‹è½½
      |_ğŸ“„ shearAirfoils.py       # å‰ªåˆ‡æ•°æ®é›†ç”Ÿæˆè„šæœ¬
      |_ğŸ“„ utils.py
    |_ğŸ“ pics                     # åŸå§‹è®ºæ–‡ç»“æœç›¸å…³å›¾ç‰‡ä»¥åŠä½œè€…å¤ç°æ‰€æ•´ç†çš„å¯¹åº”ç»“æœ
    |_ğŸ“ work                     # è®­ç»ƒè¿‡ç¨‹ã€éªŒè¯ç»“æœã€æµ‹è¯•ç»“æœï¼Œç»Ÿè®¡ç»“æœæ–‡ä»¶ä¿å­˜
      |_ğŸ“ transformer            # Results for Transformer
      |_ğŸ“ FNO				    # Results for FNO
      |_ğŸ“ UNet                   # Results for UNet utilized in original paper
  |_ğŸ“„ run_plot.py                # ç»Ÿè®¡ç»“æœç»˜åˆ¶
  |_ğŸ“„ run_statistics.py          # ç»Ÿè®¡éªŒè¯é›†æŸå¤±ã€æµ‹è¯•é›†è¯¯å·®å‡å€¼ã€æ–¹å·®
  |_ğŸ“„ run_train.py               # è®­ç»ƒè¿‡ç¨‹
  |_ğŸ“„ run_valid.py               # æµ‹è¯•è¿‡ç¨‹
  |_ğŸ“„ Trans_model.py             # äºŒç»´çš„Transformer ç»“æ„ paddleä»£ç ï¼Œæ”¯æŒå¤šç§attentionæœºåˆ¶ä»¥åŠä¸¤ç§Regressor
  |_ğŸ“„ transformer_config.yml     # config for transformer galerkin, fourier, linear, softmax and so on
  |_ğŸ“„ Unet_model.py              # åŸæ–‡ä¸­å®ç°çš„CNN-based model paddleä»£ç 
  |_ğŸ“„ FNO_model.py               # äºŒç»´çš„Fourier Neural Operator paddleä»£ç 
  ```

- **è®­ç»ƒä»¥åŠæµ‹è¯•éœ€è¦è¿›è¡Œå¦‚ä¸‹çš„å‚æ•°è®¾ç½®ï¼š**

```python
######## Settings ########

# æ€»ä½“è¿­ä»£æ­¥æ•°ï¼ŒåŸæ–‡é‡‡ç”¨80kï¼Œè¿™é‡Œé‡‡ç”¨200kï¼Œæ³¨æ„è®­ç»ƒçš„epoché‡‡ç”¨iterationsè¿›è¡Œè¿ç®—ï¼Œä»¥é¿å…ä¸åŒè®­ç»ƒé›†å¤§å°ä¼˜åŒ–æ­¥æ•°ä¸åŒ
iterations = 200000
# batch size
batch_size = 10
# learning rate, generator
lrG = 0.0005
# decay learning rate?
decayLr = True
# channel exponent to control network sizeï¼Œæ³¨æ„ä»…ç”¨äºUNetï¼Œå¯¹FNOå’ŒTransformerä¸èµ·ä½œç”¨
expo = 6
# data set config  ç¬¬ä¸€ä¸ªä½ç½®ä¸ºæ€»ä½“æ ·æœ¬æ•°é‡ï¼Œåä¸‰ä¸ªæ•°è¡¨ç¤ºä»reg/sup/shearä¸‰ä¸ªæ–‡ä»¶å¤¹é€‰æ‹©çš„æ ·æœ¬æ¯”ä¾‹ï¼Œå’Œä¸º1
# prop = None  # by default, use all from "../data/train"
prop = [10000, 1.0, 0, 0.0]  
# save txt files with per epoch loss?
saveL1 = True
# model type UNet/FNO/Transformer
net = 'Transformer'
# statistics number  æ¯ä¸ªè®­ç»ƒè¿‡ç¨‹æ‰§è¡Œæ¬¡æ•°ï¼Œä»¥ä¾¿åœ¨run_validå’Œrun_staticsticsè¿›è¡Œç»Ÿè®¡å¤šæ¬¡çš„å‡å€¼å’Œæ–¹å·®ï¼Œç»˜åˆ¶Fig10 11
sta_number = 10
# data path
data_path = os.path.join('data')

```

- **æ‰§è¡Œè¿‡ç¨‹**
  - **è¿è¡Œrun_trainï¼Œæ—¶é—´è¾ƒä¹…ï¼Œbatch_size=10ï¼Œnvidia 3090æµ‹è¯•200kå¯¹UNet expo=7 ï¼ˆå‚æ•°é‡30.9mï¼‰çº¦éœ€è¦1å°æ—¶**
  - **è¿è¡Œrun_validï¼Œè·å¾—testé›†åˆä¸Šçš„90ä¸ªcaseçš„ç»“æœäº‘å›¾ä»¥åŠå„ä¸ªè®­ç»ƒè¿‡ç¨‹çš„test relative error**
  - **è¿è¡Œrun_statisticsï¼Œè·å¾—valid loss å’Œ test relative errorç»Ÿè®¡ç»“æœå‡å€¼åŠæ–¹å·®**
  - **è¿è¡Œrun_plotï¼Œå¯¹æ‰€æœ‰ç»Ÿè®¡ç»“æœå‡å€¼åŠæ–¹å·®è¿›è¡Œç»˜å›¾ï¼Œæ–‡ä»¶ä¸­ç»™å‡ºäº†å®éªŒè¿‡ç¨‹çš„ç»Ÿè®¡ç»“æœæ–‡ä»¶**
  - **è€ƒè™‘è®­ç»ƒæ—¶é—´è¿‡ä¹…,ä¸ºå¿«é€Ÿèµ·è§ï¼Œå¯å…ˆè®¾ç½®sta_number=1ï¼Œè·‘å‡ºä¸€ç»„æŸ¥çœ‹æ•ˆæœ**

- **ç¯å¢ƒä¾èµ–**

  > numpy == 1.22.3 \
  > paddlepaddle-gpu develop \
  > matplotlib==3.5.1 \



## 2. åŸå§‹æ•°æ®é›†

æ•°æ®èŒƒå›´ï¼š ä»[UIUCæ•°æ®é›†SoIaUCAD96](https://m-selig.ae.illinois.edu/ads/coord_database.html)è·å–çš„1505ä¸ªç¿¼å‹ï¼Œ Re=[0.5, 5]Ã—10<sup>6</sup> , æ”»è§’ [-22.5, 22.5]degï¼ŒåŸæ–‡ç»™å‡ºçš„è®­ç»ƒé›†æ ·æœ¬æ€»è®¡çº¦53,830ä¸ªï¼Œæµ‹è¯•é›†90ä¸ªã€‚

æ•°æ®è·å–ï¼šOpenFOAM, æ¹æµæ¨¡å‹SAï¼Œæ•°å€¼è®¡ç®—ç½‘æ ¼åˆ’åˆ†å°ºå¯¸ä¸º1/200ï¼ˆæœºç¿¼å¼¦é•¿å›ºå®šä¸º1ï¼Œ è®¡ç®—åŸŸå°ºå¯¸ä¸º8Ã—8ï¼‰ï¼Œæ·±åº¦å­¦ä¹ å…³æ³¨åŸŸä¸ºæœºç¿¼å‘¨å›´2Ã—2ï¼Œå¹¶é‡æ–°å°†ç‰©ç†åœºæ’å€¼ä¸º128Ã—128çš„çŸ©é˜µ

æ•°æ®æè¿°ï¼š

|      | æ•°æ®æ ¼å¼      | æ•°æ®ç»„æˆ                                                     |
| ---- | ------------- | ------------------------------------------------------------ |
| è¾“å…¥ | ï¼ˆ128Ã—128ï¼‰Ã—3 | ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼Œéƒ¨åˆ†ä¸ºç½‘æ ¼ç»“æ„ä¸‹çš„æœºç¿¼å‡ ä½•mask $ \phi =0 $ è¡¨ç¤ºåœ¨æœºç¿¼å¤–éƒ¨ï¼Œ $\phi =1$ è¡¨ç¤ºåœ¨æœºç¿¼å†…éƒ¨ï¼›ç¬¬äºŒéƒ¨åˆ†ä¸º  ç”±Reå’Œæ”»è§’å†³å®šçš„åˆå§‹é€Ÿåº¦åœº $v_i = {v_{i,x}, v_{i,y}}$ |
| è¾“å‡º | ï¼ˆ128Ã—128ï¼‰Ã—3 | ç½‘æ ¼ç»“æ„ä¸‹çš„æœºç¿¼å‘¨å›´å‹å¼ºã€x-æ–¹å‘å’Œy-æ–¹å‘é€Ÿåº¦åœº  ${p_o, v_{o,x}, v_{o,y}}$ |

æ•°æ®é¢„å¤„ç†ï¼š é¦–å…ˆï¼Œé‡‡ç”¨æ¥æµæ¡ä»¶è¿›è¡Œé€Ÿåº¦å’Œå‹å¼ºå½’ä¸€åŒ–ï¼Œå¯¹äºé€Ÿåº¦è€Œè¨€ 
$$
\tilde{v}_ o = v_o/|v_i|
$$
å¯¹äºå‹å¼ºè€Œè¨€  
$$
\tilde{p}_ o = v_o/|v_i|^2
$$
å…¶æ¬¡ï¼Œå¯¹å‹å¼ºè¿›è¡ŒäºŒæ¬¡å¤„ç†ï¼Œ 
$$
\hat{p}_ {o} = \tilde{p}_ o - p_{mean}
\\ p_{mean}=\sum_{i}p_i/n
$$
æœ€åï¼Œé‡‡ç”¨æœ€å¤§æœ€å°å€¼å°†ç‰©ç†åœºæ ‡å‡†åŒ–è‡³[-1, 1]ä»¥æœ€å°åŒ–æœ‰é™æ•°å€¼ç²¾åº¦çš„è¯¯å·®ã€‚

## 3. ç½‘ç»œæ¶æ„ä»¥åŠè®­ç»ƒæ–¹æ³•

### a. ç½‘ç»œæ¶æ„

æ–‡ç« é‡‡ç”¨è§†è§‰ä¸­å¸¸ç”¨çš„UNetç»“æ„ï¼Œåœ¨è®ºæ–‡å¤ç°è¿‡ç¨‹ä¸­ï¼Œæœ¬æ–‡åŒæ—¶å¯¹æ¯”äº†Fouriour Neural operationå’ŒTransformerï¼Œè¯¦è§ç¬¬5éƒ¨åˆ†ã€‚
UNet æ„æ¶å¦‚ä¸‹å›¾æ‰€ç¤ºï¼Œå®ƒå¯ä»¥è§†ä¸ºä¸€ä¸ªç¼–ç å™¨-è§£ç å™¨æ¡†æ¶ï¼Œåœ¨ç¼–ç å™¨éƒ¨åˆ†ï¼Œå›¾ç‰‡å°ºå¯¸æŒ‰ç…§2çš„æ¯”ä¾‹é‡‡ç”¨å·ç§¯ï¼ˆstride=2ï¼‰é€æ¸ä¸‹é‡‡æ ·ï¼Œæå–ç‰¹å¾ï¼›åœ¨è§£ç å™¨éƒ¨åˆ†ï¼Œè¿›è¡Œé•œåƒæ“ä½œï¼Œé€æ¸å¢å¤§å›¾ç‰‡å°ºå¯¸ï¼Œè€Œå‡å°‘é€šé“æ•°ã€‚åœ¨å¯¹åº”å›¾ç‰‡å°ºå¯¸ä¹‹é—´è¿›è¡Œè·³è·ƒè¿æ¥ä»¥å¸®åŠ©è§£ç å™¨äº†è§£ç¼–ç å™¨è¿‡ç¨‹ä¸­çš„ä½é˜¶ä¿¡æ¯ã€‚å¯¹äº7.7mçš„UNet,ç¼–ç å™¨ä¸­ é‡‡ç”¨7ä¸ªå·ç§¯blockå°†ï¼ˆ128Ã—128ï¼‰Ã—3çš„è¾“å…¥è½¬æ¢ä¸º512ä¸ªç‰¹å¾ï¼Œå·ç§¯æ ¸å°ºå¯¸ä¸ºï¼ˆ4Ã—4ï¼‰ï¼Œæ¿€æ´»å‡½æ•°ä¸ºReLUï¼ˆSlope=0.2ï¼‰;è§£ç å™¨ä¸­é‡‡ç”¨å¯¹ç§°çš„7ä¸ªç»“æ„ï¼ˆé‡‡ç”¨æ ‡å‡†çš„ReLUï¼‰é‡æ„ä¸ºè¾“å‡ºï¼ˆ128Ã—128ï¼‰Ã—3ã€‚
![UNet-arch](https://ai-studio-static-online.cdn.bcebos.com/bd153e3f09ae41e090144920143259757923b909af584cd3b1f3cda2c56829f3)

- **æ³¨æ„ï¼šUNetç½‘ç»œç»“æ„å‚æ•°é‡é€šè¿‡expoæ§åˆ¶ï¼ŒFNOã€Transformeréœ€è¦è‡ªè¡Œè®¾ç½®ï¼Œä½¿ç”¨è€…æ ¹æ®ç›¸å…³æ–‡çŒ®è‡ªè¡Œé€‰æ‹©ã€‚**

```python
epochs = int(iterations / len(trainLoader) + 0.5)
if 'UNet' in net:
    net_model = UNet2d(channelExponent=expo, dropout=dropout)
elif 'FNO' in net:
    net_model = FNO2d(in_dim=3, out_dim=3, modes=(32, 32), width=32, depth=4, steps=1, padding=4,
                      activation='gelu')
elif 'Transformer' in net:
    import yaml

    with open(os.path.join('transformer_config.yml')) as f:
        config = yaml.full_load(f)
    config = config['Transformer']
    net_model = FourierTransformer2D(**config)
```

### b. è®­ç»ƒæ–¹æ³•

ä¸‰ç§ç½‘ç»œæ¡†æ¶é‡‡ç”¨å®Œå…¨ç›¸åŒçš„è®­ç»ƒæ–¹æ³•ï¼Œå³ Adam ä¼˜åŒ–å™¨ï¼Œ ç»Ÿä¸€è®­ç»ƒ200Kä¸ªè¿­ä»£æ­¥ï¼ŒæŸå¤±å‡½æ•°é‡‡ç”¨ $L_1$æŸå¤±ï¼š
æŸå¤±å‡½æ•°çš„å…·ä½“å…¬å¼ä¸º

| æŸå¤±å‡½æ•°   | å…¬å¼                                                         |
| ---------- | ------------------------------------------------------------ |
| x-æ–¹å‘é€Ÿåº¦ | $$ L_{vx}=\sum_{i}\|\tilde{v}_ {o,x} - \tilde{v}_ {pred, o, x}\| $$ |
| x-æ–¹å‘é€Ÿåº¦ | $L_{vy}=\sum_{i}\|\tilde{v}_ {o,y} - \tilde{v}_ {pred, o,y} \|$ |
| å‹å¼º       | $L_{p}=\sum_{i}\|\hat{p}_ {o} - \hat{p}_ {pred, o} \|$       |
| æ€»æŸå¤±å‡½æ•° | $L_{total}= (L_p + L_{vx} + L_{vy})/3$                       |

## 4. å¤ç°ç»“æœ

**å¤ç°Fig8** ä»æµ‹è¯•é›†ä¸­é€‰æ‹©è‹¥å¹²æ ·ä¾‹å±•ç¤º

| 0039                                                         | **086**                                                      | 010                                                          | 017                                                          |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![expo=7 jet 086](https://ai-studio-static-online.cdn.bcebos.com/2af2491fb15b40e092b797325cd891ae4b7cff74557a4c35b5181935d010a87f) | ![expo=7 jet 039](https://ai-studio-static-online.cdn.bcebos.com/f34981bca80a418c87945612ad7cee14943cf924b14841a89d84a589e2acbb98) | ![expo=7 jet 010](https://ai-studio-static-online.cdn.bcebos.com/e711b74f088f40b8b677781f60e869ae50623c4e642545a4b850cd6772cfff7d) | ![expo=7 jet 017](https://ai-studio-static-online.cdn.bcebos.com/ea8622a27659453bae52a5a2dce50361da4dc32685d240ebb7b1970567685d84) |

**è®ºæ–‡Fig8**

![Fig8-](https://ai-studio-static-online.cdn.bcebos.com/b36597c14c6641b795530cf9ede6f34243b25c91a44041a48edc03a96bb3a726)

**å¤ç°Fig9** ä»æµ‹è¯•é›†ä¸­é€‰æ‹©0079ç¼–å·çš„caseåœ¨ä¸åŒç½‘ç»œå‚æ•°ä¸‹çš„ç»“æœå±•ç¤º

| å‚æ•°é‡ | 1.9mï¼ˆexpo=5ï¼‰                                               | 7.7mï¼ˆexpo=6ï¼‰                                               | 30.9mï¼ˆexpo=7ï¼‰                                              |
| ------ | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| Fig9   | ![expo=7 0079](https://ai-studio-static-online.cdn.bcebos.com/d226539ee467484cbcb3d0af0cae9a9765d2214e60b04308ad0b06f6a78d715d) | ![expo=6 0079](https://ai-studio-static-online.cdn.bcebos.com/3620853d5146413dab268e600a2707e8b42f77e081344e2ea669e04af3518b9a) | ![expo=5 0079](https://ai-studio-static-online.cdn.bcebos.com/ae3f7dac197e4200adc97b2b752637b30f615459ca164ed1be506c58e0cc0c09) |

**è®ºæ–‡Fig9**

![Fig9-](https://ai-studio-static-online.cdn.bcebos.com/3aed5383003f4698a5378d067d875de697c3ce64f5a945008375319d96f8bc8f)

| ç»Ÿè®¡ç»“æœ |  å¤ç°ï¼ˆè®¡ç®—10æ¬¡ç»Ÿè®¡ç»“æœï¼‰  | è®ºæ–‡ |
| :--: | :------------: | :------: |
| Fig10 |![Fig10](https://ai-studio-static-online.cdn.bcebos.com/33344a7316434374b4f977d41dcb33da9a0cfab4644e40018bb69acfc3fce38e)| <img src="https://ai-studio-static-online.cdn.bcebos.com/3a1d7dd7c75e43b09ea7091bc88e059853bafcddd2b44f178456802085f2fbbf" alt="Fig10-" style="zoom:250%;" /> |
| Fig11 |![Fig11](https://ai-studio-static-online.cdn.bcebos.com/a066fe37138e4e66ad9d3e00fa14d432262bea787b9d46b3b17d26777363f67e)|<img src="https://ai-studio-static-online.cdn.bcebos.com/bae5a16083564e3589372d63937aae6c0a73a0e521cd4a9b8bd3d49484811852" alt="Fig11-" style="zoom:250%;" />|




## 5.æ‹“å±•å®ç°

**FNO (Fourier Neural Operator)**  

referenceï¼š[Fourier Neural Operator for Parametric Partial Differential Equations](http://arxiv.org/abs/2010.08895)

githubï¼šhttps://github.com/zongyi-li/fourier_neural_operator

![](https://ai-studio-static-online.cdn.bcebos.com/cfe9cb2617254433b78dbb6c144809e6f4b42bc85f8748cb945602e6ee424847)

Fourier Spectrual neural operator æ ¸å¿ƒç®—æ³•å®ç°è¿‡ç¨‹ï¼š

```python

class SpectralConv2d(nn.Layer):
    '''
    2ç»´è°±å·ç§¯
    Modified Zongyi Li's SpectralConv2d PyTorch 1.6 code
    using only real weights
    https://github.com/zongyi-li/fourier_neural_operator/blob/master/fourier_2d.py
    '''

    def __init__(self, in_dim,
                 out_dim,
                 modes: tuple,  # number of fourier modes
                 dropout=0.0,
                 norm='ortho',
                 activation='gelu',
                 return_freq=False):
        super(SpectralConv2d, self).__init__()

        """
        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    
        """

        self.in_dim = in_dim
        self.out_dim = out_dim
        if isinstance(modes, int):
            self.modes1 = modes  # Number of Fourier modes to multiply, at most floor(N/2) + 1
            self.modes2 = modes
        else:
            self.modes1 = modes[0]  # Number of Fourier modes to multiply, at most floor(N/2) + 1
            self.modes2 = modes[1]

        self.norm = norm
        self.dropout = nn.Dropout(dropout)
        self.activation = activation_dict[activation]
        self.return_freq = return_freq
        self.linear = nn.Conv2D(self.in_dim, self.out_dim, 1)  # for residual

        self.weights1 = paddle.create_parameter([in_dim, out_dim, self.modes1, self.modes2, 2], dtype=paddle.float32)
        w1 = params_initial('xavier_normal', shape=self.weights1.shape,
                            gain=1 / (in_dim * out_dim) * np.sqrt(in_dim + out_dim))
        self.weights1.set_value(w1)
        self.weights2 = paddle.create_parameter([in_dim, out_dim, self.modes1, self.modes2, 2], dtype=paddle.float32)
        w2 = params_initial('xavier_normal', shape=self.weights2.shape,
                            gain=1 / (in_dim * out_dim) * np.sqrt(in_dim + out_dim))
        self.weights2.set_value(w2)

    # Complex multiplication
    def compl_mul2d(self, input, weights):
        # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)
        op = partial(paddle.einsum, "bixy,ioxy->boxy")
        return paddle.stack([
            op(input[..., 0], weights[..., 0]) - op(input[..., 1], weights[..., 1]),
            op(input[..., 1], weights[..., 0]) + op(input[..., 0], weights[..., 1])
        ], axis=-1)

    def forward(self, x):
        """
        forward computation
        """
        batch_size = x.shape[0]
        # Compute Fourier coeffcients up to factor of e^(- something constant)
        res = self.linear(x)
        x = self.dropout(x)
        x_ft = paddle.fft.rfft2(x, norm=self.norm)
        x_ft = paddle.stack([x_ft.real(), x_ft.imag()], axis=-1)

        # Multiply relevant Fourier modes
        out_ft = paddle.zeros((batch_size, self.out_dim, x.shape[-2], x.shape[-1] // 2 + 1, 2), dtype=paddle.float32)
        out_ft[:, :, :self.modes1, :self.modes2] = \
            self.compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)
        out_ft[:, :, -self.modes1:, :self.modes2] = \
            self.compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)
        out_ft = paddle.complex(out_ft[..., 0], out_ft[..., 1])

        # Return to physical space
        x = paddle.fft.irfft2(out_ft, s=(x.shape[-2], x.shape[-1]), norm=self.norm)
        x = self.activation(x + res)

        if self.return_freq:
            return x, out_ft
        else:
            return x
```

**Garlerkin Transformer**

referenceï¼š[Choose a Transformer: Fourier or Galerkin](http://arxiv.org/abs/2010.08895)

githubï¼šhttps://github.com/scaomath/galerkin-transformer

æœ¬æ–‡ä¸­æå‡ºäº†ä¸åŸå§‹attentionæœºåˆ¶çš„æ”¹è¿›æ–¹æ³•ï¼Œç±»æ¯”æœ‰é™å…ƒæ–¹æ³•ï¼Œè¿‘ä¼¼çº¿æ€§åŒ–é™ä½äº†è®¡ç®—å¤æ‚åº¦ï¼Œæå‡äº†è®¡ç®—æ•ˆç‡ã€‚ç½‘ç»œçš„è¯¦ç»†è®¾ç½®

![Trans-arch](https://ai-studio-static-online.cdn.bcebos.com/5afd294cfd6447189d5c655870f2d0706a05815e03944380835c44b70008d245)

| å½¢å¼     | attentionè®¡ç®—æ–¹å¼                                            |                                                              |
| -------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| fourier  | ![Trans-fourier](https://ai-studio-static-online.cdn.bcebos.com/a62efc6b06d3441492c507b1c381521fe474fcf9eed94ee6b53a7c36cd24184b) | <img src="https://ai-studio-static-online.cdn.bcebos.com/e1efb1c56a0c44ef8b32d8c4d2e8e3c529e70800c13e4547aceafefa440bfe8a" alt="Trans-fourier_" style="zoom:50%;" /> |
| galerkin | ![Trans-galerkin](https://ai-studio-static-online.cdn.bcebos.com/d23dcfa98ce34bf9a22d9a471a5bb8cf370e064dc53248fcbe0dae87b1e6c0cf) | <img src="https://ai-studio-static-online.cdn.bcebos.com/e1efb1c56a0c44ef8b32d8c4d2e8e3c529e70800c13e4547aceafefa440bfe8a" alt="Transformer_galerkin_" style="zoom:50%;" /> |

æ”¹è¿›çš„attentionæœºåˆ¶æ ¸å¿ƒç®—æ³•å®ç°è¿‡ç¨‹ï¼šï¼ˆåŒ…æ‹¬fourier,galerkin,linear,softmaxï¼‰

```python

class SimpleAttention(nn.Layer):
    '''
    The attention is using a vanilla (QK^T)V or Q(K^T V) with no softmax
    For an encoder layer, the tensor size is slighly different from the official pytorch implementation

    attn_types:
        - fourier: integral, local
        - galerkin: global
        - linear: standard linearization
        - softmax: classic softmax attention

    In this implementation, output is (N, L, E).
    batch_first will be added in the next version of PyTorch: https://github.com/pytorch/pytorch/pull/55285

    Reference: code base modified from
    https://nlp.seas.harvard.edu/2018/04/03/attention.html
    - added xavier init gain
    - added layer norm <-> attn norm switch
    - added diagonal init

    In https://github.com/lucidrains/linear-attention-transformer/blob/master/linear_attention_transformer/linear_attention_transformer.py
    the linear attention in each head is implemented as an Einstein sum
    attn_matrix = paddle.einsum('bhnd,bhne->bhde', k, v)
    attn = paddle.einsum('bhnd,bhde->bhne', q, attn_matrix)
    return attn.reshape(*q.shape)
    here in our implementation this is achieved by a slower transpose+matmul
    but can conform with the template Harvard NLP gave
    '''

    def __init__(self, n_head, d_model,
                 pos_dim: int = 1,
                 attention_type='fourier',
                 dropout=0.1,
                 xavier_init=1e-4,
                 diagonal_weight=1e-2,
                 symmetric_init=False,
                 norm_add=False,
                 norm_type='layer',
                 eps=1e-5):
        super(SimpleAttention, self).__init__()
        assert d_model % n_head == 0  # n_head å¯è¢«d_modelæ•´é™¤
        self.attention_type = attention_type
        self.d_k = d_model // n_head
        self.n_head = n_head
        self.pos_dim = pos_dim
        self.linears = nn.LayerList(
            [copy.deepcopy(nn.Linear(d_model, d_model)) for _ in range(3)])
        self.xavier_init = xavier_init
        self.diagonal_weight = diagonal_weight
        self.symmetric_init = symmetric_init
        if self.xavier_init > 0:
            self._reset_parameters()
        self.norm_add = norm_add
        self.norm_type = norm_type
        if norm_add:
            self._get_norm(eps=eps)

        if pos_dim > 0:
            self.fc = nn.Linear(d_model + n_head * pos_dim, d_model)

        self.attn_weight = None
        self.dropout = nn.Dropout(dropout)

    def forward(self, query, key, value, pos=None, mask=None, weight=None):
        """
        forward compute
        :param query: (batch, seq_len, d_model)
        :param key: (batch, seq_len, d_model)
        :param value: (batch, seq_len, d_model)
        """
        if mask is not None:
            mask = mask.unsqueeze(1)

        bsz = query.shape[0]
        if weight is not None:
            query, key = weight * query, weight * key

        query, key, value = \
            [layer(x).reshape((bsz, -1, self.n_head, self.d_k)).transpose((0, 2, 1, 3))
             for layer, x in zip(self.linears, (query, key, value))]

        if self.norm_add:
            if self.attention_type in ['linear', 'galerkin', 'global']:
                if self.norm_type == 'instance':
                    key, value = key.transpose((0, 1, 3, 2)), value.transpose((0, 1, 3, 2))

                key = paddle.stack(
                    [norm(x) for norm, x in
                     zip(self.norm_K, (key[:, i, ...] for i in range(self.n_head)))], axis=1)
                value = paddle.stack(
                    [norm(x) for norm, x in
                     zip(self.norm_V, (value[:, i, ...] for i in range(self.n_head)))], axis=1)

                if self.norm_type == 'instance':
                    key, value = key.transpose((0, 1, 3, 2)), value.transpose((0, 1, 3, 2))
            else:
                if self.norm_type == 'instance':
                    key, query = key.transpose((0, 1, 3, 2)), query.transpose((0, 1, 3, 2))

                key = paddle.stack(
                    [norm(x) for norm, x in
                     zip(self.norm_K, (key[:, i, ...] for i in range(self.n_head)))], axis=1)
                query = paddle.stack(
                    [norm(x) for norm, x in
                     zip(self.norm_Q, (query[:, i, ...] for i in range(self.n_head)))], axis=1)

                if self.norm_type == 'instance':
                    key, query = key.transpose((0, 1, 3, 2)), query.transpose((0, 1, 3, 2))

        if pos is not None and self.pos_dim > 0:
            assert pos.shape[-1] == self.pos_dim
            pos = pos.unsqueeze(1)
            pos = pos.tile([1, self.n_head, 1, 1])
            query, key, value = [paddle.concat([pos, x], axis=-1)
                                 for x in (query, key, value)]

        if self.attention_type in ['linear', 'galerkin', 'global']:
            x, self.attn_weight = linear_attention(query, key, value,
                                                   mask=mask,
                                                   attention_type=self.attention_type,
                                                   dropout=self.dropout)
        else:
            x, self.attn_weight = vanilla_attention(query, key, value,
                                                    mask=mask,
                                                    attention_type=self.attention_type,
                                                    dropout=self.dropout)

        out_dim = self.n_head * self.d_k if pos is None else self.n_head * \
                                                             (self.d_k + self.pos_dim)
        att_output = x.transpose((0, 2, 1, 3)).reshape((bsz, -1, out_dim))

        if pos is not None and self.pos_dim > 0:
            att_output = self.fc(att_output)

        return att_output, self.attn_weight

```



## 6. ä¸‰ç§ç½‘ç»œæ¶æ„å¯¹æ¯”

åœ¨25600çš„è®­ç»ƒæ ·æœ¬ä¸‹ï¼Œä¸‰ç§ç½‘ç»œåˆ†åˆ«è®­ç»ƒiterations=100kï¼Œç»“æœå¦‚å›¾

| Model | UNet                                                         | FNO                                                          | Transformer-galerkin                                         |
| ----- | ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| 0079  | ![img](https://ai-studio-static-online.cdn.bcebos.com/d226539ee467484cbcb3d0af0cae9a9765d2214e60b04308ad0b06f6a78d715d) | ![FNO](https://ai-studio-static-online.cdn.bcebos.com/e551ee5aac514f2bbad002d6ed5b6e6f00312b3118c7459cac0c7e7d2a10d058) | ![Trans](https://ai-studio-static-online.cdn.bcebos.com/630ffc91bedf47bb888764209b6beb6c220badb40e834ac081418524a12c9990) |
| 0004  | ![UNet004](https://ai-studio-static-online.cdn.bcebos.com/24b1b935d83347c3b9ee8f4dc9a19e761c5ee99d366b4470a9936a5c20ed591b) | ![FNO004](https://ai-studio-static-online.cdn.bcebos.com/fbb9366b69004e22b5d268a7b7f270dbc8caea1b3c514c45b3d962bbe7b7df1e) | ![Trans004](https://ai-studio-static-online.cdn.bcebos.com/97aaefedb013417d979a1d4fd5b1aec0165d91abd7e94e96adc4e2dc00715282) |
| æŒ‡æ ‡  | Loss percentage (p, v, combined): 24.304499 %    4.075242 %    5.419715 % L1 error: 0.011459<br/>Denormalized error: 0.032662 | Loss percentage (p, v, combined): 9.744780 %    1.717354 %    2.072256 % L1 error: 0.004192<br/>Denormalized error: 0.009566 | Loss percentage (p, v, combined): 9.847503 %    1.739543 %    2.105041 % <br/>L1 error: 0.004261<br/>Denormalized error: 0.010268 |

ä¸åŒè®­ç»ƒé›†å¤§å°ä¸‹ï¼Œè¿è¡Œ10æ¬¡ç»Ÿè®¡ç»“æœï¼š

![comp](https://ai-studio-static-online.cdn.bcebos.com/7ac5d8377d374209a4b89ed8b5924afdb671902e78cd48369bac660e2a0e26e9)

æœ¬æ¬¡æµ‹è¯•æµ‹è¯•ç»“æœè¿›è¡Œäº†ä¸€ä¸ªç®€å•çš„å¯¹æ¯”ï¼ŒFNOå’ŒTransformerä¼˜äºUNetï¼Œä¹Ÿä¼˜äºåŸå§‹è®ºæ–‡ä¸­çš„æœ€ä½³å€¼ï¼Œä½†è¿™ä¸ªç»“è®ºå€¼å¾—è¿›ä¸€æ­¥è®¨è®ºã€‚äº‹å®ä¸Šï¼Œæœ¬æ¬¡å®Œæˆçš„Transformerä¸­æä¾›äº†å¤šç§attentionæœºåˆ¶ï¼Œä»¥åŠä¸åŒçš„Regressorï¼Œå¯¹äºFNOå’ŒTransformerä»¥åŠæ›´å¤šç®—å­å­¦ä¹ æ–¹æ³•çš„é€Ÿåº¦ã€ç²¾åº¦å’Œç¨³å®šæ€§çš„å¯¹æ¯”å¯ä»¥åœ¨è¿™ä¸ªæ ‡å‡†æ•°æ®é›†ä¸Šå±•å¼€ï¼Œå®Œæˆç±»ä¼¼[PDEBench](http://arxiv.org/abs/2210.07182)ä¸­çš„å·¥ä½œã€‚

**æœ¬æ¬¡ä»£ç ä»…ä»…æŠ›ç –å¼•ç‰ï¼ŒæœŸå¾…æœ‰å…´è¶£çš„ä½¿ç”¨è€…åœ¨æ­¤åŸºç¡€ä¸Šè¿›è¡Œè¿›ä¸€æ­¥æ¢ç´¢ã€‚**

## 7. æ¨¡å‹ä¿¡æ¯

| ä¿¡æ¯          | è¯´æ˜                                                      |      |
| ------------- | --------------------------------------------------------- | ---- |
| å‘å¸ƒè€…        | tianshao1992                                              |      |
| æ—¶é—´          | 2023.3                                                    |      |
| æ¡†æ¶ç‰ˆæœ¬      | Paddle Develope                                           |      |
| åº”ç”¨åœºæ™¯      | ç§‘å­¦è®¡ç®—                                                  |      |
| æ”¯æŒç¡¬ä»¶      | CPUã€GPU                                                  |      |
| AI studioåœ°å€ | https://aistudio.baidu.com/aistudio/projectdetail/5584432 |      |
